{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295bd7a-8bcb-4726-8d28-8cc98bccc693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c63bb85-940a-4e2d-816e-bf9c7da5d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d8a1eb1-a731-4359-9d05-4bba47e17d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUG_PROB = 0.75\n",
    "IMG_SIZE = [512, 512]\n",
    "IN_CHANS = 25\n",
    "N_LABELS = 25\n",
    "N_CLASSES = 3 * N_LABELS\n",
    "N_FOLDS = 5\n",
    "EPOCHS = 20 \n",
    "MODEL_NAME = \"tf_efficientnet_b3.ns_jft_in1k\"\n",
    "USE_AMP = True\n",
    "SEED = 8620\n",
    "N_WORKERS=4\n",
    "device=\"cuda:0\"\n",
    "\n",
    "OUTPUT_DIR=\"tmp-models\"\n",
    "\n",
    "GRAD_ACC = 2\n",
    "TGT_BATCH_SIZE = 32\n",
    "BATCH_SIZE = TGT_BATCH_SIZE // GRAD_ACC\n",
    "MAX_GRAD_NORM = None\n",
    "EARLY_STOPPING_EPOCH = 3\n",
    "\n",
    "LR = 2e-4 * TGT_BATCH_SIZE / 32\n",
    "WD = 1e-2\n",
    "AUG = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f77e761-6197-4f88-8e1d-076aa4f114ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNA24Dataset(Dataset):\n",
    "    def __init__(self, df, phase='train', transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        x = np.zeros((512, 512, IN_CHANS), dtype=np.uint8)\n",
    "\n",
    "        patient_id = self.df.iloc[idx][\"study_id\"]\n",
    "        label = self.df.iloc[idx][1:].values.astype(np.int64)\n",
    "        patient_info_path = f\"./processed-dataset/{patient_id}.pkl\"\n",
    "\n",
    "        with open(patient_info_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        scans_used = []\n",
    "\n",
    "        for series_info in data[\"series\"].values():\n",
    "\n",
    "            scan_type = series_info[\"series_description\"]\n",
    "\n",
    "            if scan_type in scans_used:\n",
    "                continue\n",
    "\n",
    "            scans = series_info[\"images\"]\n",
    "\n",
    "            if scan_type == \"Sagittal T2/STIR\":\n",
    "\n",
    "                for i in range(min(10, len(scans))):\n",
    "                    x[..., i] = scans[i][\"img\"].astype(np.uint8)\n",
    "\n",
    "            elif scan_type == \"Sagittal T1\":\n",
    "\n",
    "                for i in range(min(10, len(scans))):\n",
    "                    x[..., i+10] = scans[i][\"img\"].astype(np.uint8)\n",
    "\n",
    "            elif scan_type == \"Axial T2\":\n",
    "\n",
    "                for i in range(min(5,len(scans))):\n",
    "                    x[..., i+20] = scans[i][\"img\"].astype(np.uint8)\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(f\"unknown series_description: {series_info[\"series_description\"]}\")\n",
    "\n",
    "            scans_used.append(scan_type)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(image=x)['image']\n",
    "\n",
    "        x = x.transpose(2, 0, 1)\n",
    "\n",
    "        return x, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ccd3b-adaa-4116-a951-0aa574f87137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42e672cc-94ec-4de0-8920-62673bdc41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df.fillna(-100)\n",
    "label2id = {'Normal/Mild': 0, 'Moderate':1, 'Severe':2}\n",
    "df = df.replace(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49e01b1a-bcb3-452b-8e6d-978c768e5126",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = A.Compose([\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=AUG_PROB),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=5),\n",
    "        A.MedianBlur(blur_limit=5),\n",
    "        A.GaussianBlur(blur_limit=5),\n",
    "        A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "    ], p=AUG_PROB),\n",
    "\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(distort_limit=1.0),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "        A.ElasticTransform(alpha=3),\n",
    "    ], p=AUG_PROB),\n",
    "\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=AUG_PROB),\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "    A.CoarseDropout(max_holes=16, max_height=64, max_width=64, min_holes=1, min_height=8, min_width=8, p=AUG_PROB),    \n",
    "    A.Normalize(mean=0.5, std=0.5)\n",
    "])\n",
    "\n",
    "transforms_val = A.Compose([\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "    A.Normalize(mean=0.5, std=0.5)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15897929-b37d-4d1f-a156-c81c49347fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ds = RSNA24Dataset(df, phase='train', transform=transforms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "175c8923-9ddb-470a-b0b8-9c283fa98ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNA24Model(nn.Module):\n",
    "    def __init__(self, model_name, in_c=30, n_classes=75, pretrained=True, features_only=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\n",
    "                                    model_name,\n",
    "                                    pretrained=pretrained, \n",
    "                                    features_only=features_only,\n",
    "                                    in_chans=in_c,\n",
    "                                    num_classes=n_classes,\n",
    "                                    global_pool='avg'\n",
    "                                    )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.model(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9c6b886-c702-47e5-9844-15e8d89f1392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75]) tensor(-1.1415, grad_fn=<MinBackward1>) tensor(1.2957, grad_fn=<MaxBackward1>)\n",
      "torch.Size([75]) tensor(-1.4127, grad_fn=<MinBackward1>) tensor(1.2413, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "m = RSNA24Model(MODEL_NAME, in_c=IN_CHANS, n_classes=N_CLASSES, pretrained=False)\n",
    "i = torch.randn(2, IN_CHANS, 512, 512)\n",
    "out = m(i)\n",
    "for o in out:\n",
    "    print(o.shape, o.min(), o.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d13dee2-dc2c-40ad-8498-8642e6189691",
   "metadata": {},
   "outputs": [],
   "source": [
    "del m, i, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fd2c483-87d4-438d-912d-dc8fe0ec8163",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP, init_scale=4096)\n",
    "skf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54c5fbd5-e9bf-4736-a11f-5a31ac5c986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57b9db21-1ce4-4184-80ab-cb01f883a854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/tf_efficientnet_b3.ns_jft_in1k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "start fold0\n",
      "##############################\n",
      "1580 395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._hub:[timm/tf_efficientnet_b3.ns_jft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:timm.models._builder:Converted input conv conv_stem pretrained weights from 3 to 25 channel(s)\n",
      "INFO:timm.models._builder:Missing keys (classifier.weight, classifier.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:50<00:00,  1.96it/s, loss=0.993940, lr=9.796e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.998182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:05<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss:0.820861, val_wll:0.876380\n",
      "epoch:1, best loss updated from 1.200000 to 0.820861\n",
      "epoch:1, best wll_metric updated from 1.200000 to 0.876380\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory tmp-models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 149\u001b[0m\n\u001b[1;32m    147\u001b[0m     best_wll \u001b[38;5;241m=\u001b[39m val_wll\n\u001b[1;32m    148\u001b[0m     fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/best_wll_model_fold-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    152\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/serialization.py:627\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    624\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    628\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/serialization.py:501\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/serialization.py:472\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory tmp-models does not exist."
     ]
    }
   ],
   "source": [
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(range(len(df)))):\n",
    "    print('#'*30)\n",
    "    print(f'start fold{fold}')\n",
    "    print('#'*30)\n",
    "    print(len(trn_idx), len(val_idx))\n",
    "    df_train = df.iloc[trn_idx]\n",
    "    df_valid = df.iloc[val_idx]\n",
    "\n",
    "    train_ds = RSNA24Dataset(df_train, phase='train', transform=transforms_train)\n",
    "    train_dl = DataLoader(\n",
    "                train_ds,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                pin_memory=True,\n",
    "                drop_last=True,\n",
    "                num_workers=N_WORKERS\n",
    "                )\n",
    "\n",
    "    valid_ds = RSNA24Dataset(df_valid, phase='valid', transform=transforms_val)\n",
    "    valid_dl = DataLoader(\n",
    "                valid_ds,\n",
    "                batch_size=BATCH_SIZE*2,\n",
    "                shuffle=False,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "                num_workers=N_WORKERS\n",
    "                )\n",
    "\n",
    "    model = RSNA24Model(MODEL_NAME, IN_CHANS, N_CLASSES, pretrained=True)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "    warmup_steps = EPOCHS/10 * len(train_dl) // GRAD_ACC\n",
    "    num_total_steps = EPOCHS * len(train_dl) // GRAD_ACC\n",
    "    num_cycles = 0.475\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=warmup_steps,\n",
    "                                                num_training_steps=num_total_steps,\n",
    "                                                num_cycles=num_cycles)\n",
    "\n",
    "    weights = torch.tensor([1.0, 2.0, 4.0])\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "    criterion2 = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "    best_loss = 1.2\n",
    "    best_wll = 1.2\n",
    "    es_step = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print(f'start epoch {epoch}')\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        with tqdm(train_dl, leave=True) as pbar:\n",
    "            optimizer.zero_grad()\n",
    "            for idx, (x, t) in enumerate(pbar):  \n",
    "                x = x.to(device)\n",
    "                t = t.to(device)\n",
    "\n",
    "                # print(t)\n",
    "                \n",
    "                with autocast:\n",
    "                    loss = 0\n",
    "                    y = model(x)\n",
    "                    for col in range(N_LABELS):\n",
    "                        pred = y[:,col*3:col*3+3]\n",
    "                        gt = t[:,col]\n",
    "                        loss = loss + criterion(pred, gt) / N_LABELS\n",
    "\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    if GRAD_ACC > 1:\n",
    "                        loss = loss / GRAD_ACC\n",
    "    \n",
    "                if not math.isfinite(loss):\n",
    "                    print(f\"Loss is {loss}, stopping training\")\n",
    "                    sys.exit(1)\n",
    "    \n",
    "                pbar.set_postfix(\n",
    "                    OrderedDict(\n",
    "                        loss=f'{loss.item()*GRAD_ACC:.6f}',\n",
    "                        lr=f'{optimizer.param_groups[0][\"lr\"]:.3e}'\n",
    "                    )\n",
    "                )\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM or 1e9)\n",
    "                \n",
    "                if (idx + 1) % GRAD_ACC == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    if scheduler is not None:\n",
    "                        scheduler.step()                    \n",
    "    \n",
    "        train_loss = total_loss/len(train_dl)\n",
    "        print(f'train_loss:{train_loss:.6f}')\n",
    "\n",
    "        total_loss = 0\n",
    "        y_preds = []\n",
    "        labels = []\n",
    "        \n",
    "        model.eval()\n",
    "        with tqdm(valid_dl, leave=True) as pbar:\n",
    "            with torch.no_grad():\n",
    "                for idx, (x, t) in enumerate(pbar):\n",
    "                    \n",
    "                    x = x.to(device)\n",
    "                    t = t.to(device)\n",
    "                        \n",
    "                    with autocast:\n",
    "                        loss = 0\n",
    "                        loss_ema = 0\n",
    "                        y = model(x)\n",
    "                        for col in range(N_LABELS):\n",
    "                            pred = y[:,col*3:col*3+3]\n",
    "                            gt = t[:,col]\n",
    " \n",
    "                            loss = loss + criterion(pred, gt) / N_LABELS\n",
    "                            y_pred = pred.float()\n",
    "                            y_preds.append(y_pred.cpu())\n",
    "                            labels.append(gt.cpu())\n",
    "                        \n",
    "                        total_loss += loss.item()   \n",
    "    \n",
    "        val_loss = total_loss/len(valid_dl)\n",
    "        \n",
    "        y_preds = torch.cat(y_preds, dim=0)\n",
    "        labels = torch.cat(labels)\n",
    "        val_wll = criterion2(y_preds, labels)\n",
    "        \n",
    "        print(f'val_loss:{val_loss:.6f}, val_wll:{val_wll:.6f}')\n",
    "\n",
    "        if val_loss < best_loss or val_wll < best_wll:\n",
    "            \n",
    "            es_step = 0\n",
    "\n",
    "            if device!='cuda:0':\n",
    "                model.to('cuda:0')                \n",
    "                \n",
    "            if val_loss < best_loss:\n",
    "                print(f'epoch:{epoch}, best loss updated from {best_loss:.6f} to {val_loss:.6f}')\n",
    "                best_loss = val_loss\n",
    "                \n",
    "            if val_wll < best_wll:\n",
    "                print(f'epoch:{epoch}, best wll_metric updated from {best_wll:.6f} to {val_wll:.6f}')\n",
    "                best_wll = val_wll\n",
    "                fname = f'{OUTPUT_DIR}/best_wll_model_fold-{fold}.pt'\n",
    "                torch.save(model.state_dict(), fname)\n",
    "            \n",
    "            if device!='cuda:0':\n",
    "                model.to(device)\n",
    "            \n",
    "        else:\n",
    "            es_step += 1\n",
    "            if es_step >= EARLY_STOPPING_EPOCH:\n",
    "                print('early stopping')\n",
    "                break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58dd45db-5e4b-4be0-a285-9c31620f4bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "start fold0\n",
      "##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:06<00:00, 64.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "start fold1\n",
      "##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:05<00:00, 67.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "start fold2\n",
      "##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:05<00:00, 65.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "start fold3\n",
      "##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:05<00:00, 68.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "start fold4\n",
      "##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:06<00:00, 65.69it/s]\n"
     ]
    }
   ],
   "source": [
    "cv = 0\n",
    "y_preds = []\n",
    "labels = []\n",
    "weights = torch.tensor([1.0, 2.0, 4.0])\n",
    "criterion2 = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(range(len(df)))):\n",
    "    print('#'*30)\n",
    "    print(f'start fold{fold}')\n",
    "    print('#'*30)\n",
    "    df_valid = df.iloc[val_idx]\n",
    "    valid_ds = RSNA24Dataset(df_valid, phase='valid', transform=transforms_val)\n",
    "    valid_dl = DataLoader(\n",
    "                valid_ds,\n",
    "                batch_size=1,\n",
    "                shuffle=False,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "                num_workers=N_WORKERS\n",
    "                )\n",
    "\n",
    "    model = RSNA24Model(MODEL_NAME, IN_CHANS, N_CLASSES, pretrained=False)\n",
    "    fname = f'{OUTPUT_DIR}/best_wll_model_fold-{fold}.pt'\n",
    "    model.load_state_dict(torch.load(fname))\n",
    "    model.to(device)   \n",
    "    \n",
    "    model.eval()\n",
    "    with tqdm(valid_dl, leave=True) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for idx, (x, t) in enumerate(pbar):\n",
    "                \n",
    "                x = x.to(device)\n",
    "                t = t.to(device)\n",
    "                    \n",
    "                with autocast:\n",
    "                    y = model(x)\n",
    "                    for col in range(N_LABELS):\n",
    "                        pred = y[:,col*3:col*3+3]\n",
    "                        gt = t[:,col] \n",
    "                        y_pred = pred.float()\n",
    "                        y_preds.append(y_pred.cpu())\n",
    "                        labels.append(gt.cpu())\n",
    "\n",
    "y_preds = torch.cat(y_preds)\n",
    "labels = torch.cat(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f21a2c71-b2de-4414-b210-8616c072e669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: 0.70913165807724\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cv = criterion2(y_preds, labels)\n",
    "print('cv score:', cv.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8ab43-30ce-49df-baad-c12cc1f24ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
