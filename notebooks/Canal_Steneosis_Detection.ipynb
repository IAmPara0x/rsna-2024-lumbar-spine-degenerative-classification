{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30bc5f9a-a2e2-40ea-a796-dbcd63d8b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from enum import StrEnum\n",
    "import random\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "from lib import *\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41efade-c281-4da3-8755-88e74ca21b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEBUG = False\n",
    "DATA_DIR = \"./processed-data/sagittal_t2_stir_segmentation\"\n",
    "MODEL_NAME = \"tf_efficientnet_b0.ns_jft_in1k\" if DEBUG else \"tf_efficientnet_b5.ns_jft_in1k\"\n",
    "DEVICE = \"cuda:0\"\n",
    "MODEL_DIR = \"./models/sagittial_t2_stir\"\n",
    "\n",
    "EPOCHS = 15\n",
    "\n",
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "\n",
    "# Network params\n",
    "N_CLASSES = 5\n",
    "HIDDEN_DIM = 768\n",
    "LOCATION_DIM = 10\n",
    "\n",
    "\n",
    "SEED = 8620\n",
    "N_WORKERS=4\n",
    "\n",
    "GRAD_ACC = 1\n",
    "TGT_BATCH_SIZE = 16\n",
    "BATCH_SIZE = TGT_BATCH_SIZE // GRAD_ACC\n",
    "EARLY_STOPPING_EPOCH = 3\n",
    "OUTPUT_DIR = \"models/sagittial_t2_stir\"\n",
    "\n",
    "\n",
    "TEST_BATCH_SIZE = 1\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "LR = 2e-4 * TGT_BATCH_SIZE / 32\n",
    "AUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9467ad99-128e-444f-8405-9f42f1d165f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "PATH = f\"./processed-data/sagittal_t2_stir_segmentation/\"\n",
    "patient_ids = [*map(lambda p: int(os.path.basename(p).split(\".\")[0]), glob.glob(f\"{PATH}/*.pkl\"))]\n",
    "\n",
    "df = df[df[\"study_id\"].isin(patient_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44892920-adc7-4cc4-bf5b-02363dc6ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vertical_flip(img, coord):\n",
    "    new_coord = coord.copy()\n",
    "    img = cv2.flip(img, 0)  # 0 for vertical flip\n",
    "    new_coord[:, 1] = img.shape[1] - new_coord[:, 1]  # Adjusting the y-coordinates for vertical flip\n",
    "    return img, new_coord\n",
    "\n",
    "def horizontal_flip(img, coord):\n",
    "    new_coord = coord.copy()\n",
    "    img = cv2.flip(img, 1)  # Corrected to 1 for horizontal flip\n",
    "    new_coord[:, 0] = img.shape[0] - new_coord[:, 0]  # Adjusting the x-coordinates for horizontal flip\n",
    "    return img, new_coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1df0d04-1825-47a9-b4dd-0e2b308ee156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNA24Dataset(Dataset):\n",
    "    def __init__(self, patient_ids, transformations=[], phase=\"train\", positive_negative_ratio=0.5, positive_augment_prob=0.25, negative_augment_prob=0.15):\n",
    "        self.patient_ids = patient_ids\n",
    "        self.transformations = transformations\n",
    "        self.positive_negative_ratio = positive_negative_ratio\n",
    "        self.positive_augment_prob = positive_augment_prob\n",
    "        self.negative_augment_prob = negative_augment_prob\n",
    "        self.phase = phase\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.patient_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        patient_id = self.patient_ids[idx]\n",
    "\n",
    "        patient_info_path = f\"{DATA_DIR}/{patient_id}.pkl\"\n",
    "\n",
    "        with open(patient_info_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        sagittal_t2_stir = [*data[\"series\"].values()]\n",
    "\n",
    "        if len(sagittal_t2_stir) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            sagittal_t2_stir = sagittal_t2_stir[0]\n",
    "\n",
    "\n",
    "        if self.phase == \"train\":\n",
    "            \n",
    "            y_class = np.zeros(5)\n",
    "            y_loc = np.zeros((5,2))\n",
    "            \n",
    "            if random.random() <= self.positive_negative_ratio:\n",
    "                imgs = [img for img in sagittal_t2_stir[\"images\"] if len(img[\"labels\"]) != 0]\n",
    "                has_sampled_postive_label = True\n",
    "            else:\n",
    "                imgs = [img for img in sagittal_t2_stir[\"images\"] if len(img[\"labels\"]) == 0]\n",
    "                has_sampled_postive_label = False\n",
    "                \n",
    "            img =  random.choice(imgs) if len(imgs) != 0 else random.choice(sagittal_t2_stir[\"images\"])\n",
    "            x = img[\"img\"].astype(np.float32)\n",
    "    \n",
    "            for label in img[\"labels\"]:\n",
    "                y_loc[label.level - 1] = np.array([label.x, label.y])\n",
    "                y_class[label.level - 1] = 1\n",
    "    \n",
    "            aug_prob = self.positive_augment_prob if has_sampled_postive_label else self.negative_augment_prob\n",
    "            x,y_loc = self.transform(x, y_class, y_loc,aug_prob)\n",
    "    \n",
    "            x = x / 255\n",
    "            x = np.expand_dims(x, 0)\n",
    "    \n",
    "            return x, (y_class,y_loc)\n",
    "            \n",
    "        else:\n",
    "            imgs = sagittal_t2_stir[\"images\"]\n",
    "            num_imgs = len(imgs)\n",
    "            xs = np.zeros((num_imgs, HEIGHT, WIDTH))\n",
    "            \n",
    "            y_classes = np.zeros((num_imgs, 5))\n",
    "            y_locs = np.zeros((num_imgs, 5, 2))\n",
    "\n",
    "            for idx,img in enumerate(imgs):\n",
    "                xs[idx] = img[\"img\"].astype(np.float32)\n",
    "                \n",
    "                for label in img[\"labels\"]:\n",
    "                    y_locs[idx, label.level - 1] = np.array([label.x, label.y])\n",
    "                    y_classes[idx, label.level - 1] = 1\n",
    "            xs = xs / 255\n",
    "            xs = np.expand_dims(xs, 1)\n",
    "            return xs, (y_classes, y_locs)\n",
    "            \n",
    "\n",
    "\n",
    "    def transform(self, x, y_class, y_loc, aug_prob):\n",
    "        for transformation in self.transformations:\n",
    "            if random.random() <= aug_prob:\n",
    "                x,y_loc = transformation(x,y_loc)\n",
    "                y_loc = np.expand_dims(y_class, 1) * y_loc\n",
    "                    \n",
    "        return x, y_loc\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2033e07f-c7d9-4dcb-a989-429329fb5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AvgPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self,x):\n",
    "\n",
    "        r = list(x.shape)[:-2]\n",
    "        r.append(-1)\n",
    "        x = x.reshape(tuple(r)).mean(dim=-1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class RSNA24Model(nn.Module):\n",
    "    def __init__(self, model_name, n_classes=N_CLASSES, location_dim=LOCATION_DIM, hidden_dim=HIDDEN_DIM, pretrained=True, features_only=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_features  = 512\n",
    "        self.img_features_dim = 2048\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.location_dim = location_dim\n",
    "\n",
    "        self.initial_conv = nn.Conv2d(1,3, (3,3), stride=(1,1), padding=(1,1))\n",
    "        self.feature_extractor =  timm.create_model( model_name , pretrained=pretrained , features_only=features_only, out_indices=[-1] )\n",
    "\n",
    "        self.predictors = nn.Sequential(\n",
    "            nn.Conv2d(self.img_features, self.img_features, (3,3), stride=(1,1), padding=(1,1)),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(self.img_features, self.img_features_dim, (1,1), stride=(1,1), bias=False),\n",
    "            nn.BatchNorm2d(self.img_features_dim),\n",
    "            AvgPool(),\n",
    "            nn.Linear(self.img_features_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, self.n_classes)\n",
    "        )\n",
    "\n",
    "        self.location_predictor = nn.Sequential(\n",
    "            nn.Conv2d(self.img_features, self.img_features, (3,3), stride=(1,1), padding=(1,1)),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(self.img_features, self.img_features, (3,3), stride=(1,1), padding=(1,1)),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(self.img_features, self.img_features_dim, (1,1), stride=(1,1), bias=False),\n",
    "            nn.BatchNorm2d(self.img_features_dim),\n",
    "            AvgPool(),\n",
    "            nn.Linear(self.img_features_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, self.location_dim)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x, freeze_conv=False):\n",
    "        x = self.initial_conv(x)\n",
    "\n",
    "        if freeze_conv:\n",
    "            with torch.no_grad():\n",
    "                x = self.feature_extractor(x)[0]\n",
    "        else:\n",
    "            x = self.feature_extractor(x)[0]\n",
    "            \n",
    "        class_preds = self.predictors(x)\n",
    "        location_preds = self.location_predictor(x)\n",
    "        return class_preds, location_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b854726-8e1a-4a80-b8d4-18ddb54bd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "def criterion(y_class, y_loc, pred_class, pred_loc, alpha=0.01):\n",
    "    \n",
    "    class_loss = bce(pred_class, y_class)\n",
    "    \n",
    "    loc_loss = (((pred_loc - y_loc) ** 2).sum(-1).sqrt() * y_class).mean(-1).mean()\n",
    "\n",
    "    # deviation_loss = ((pred_loc[:, :-1, :] - pred_loc[:, 1:, :]) ** 2).sum(dim=-1).sqrt()\n",
    "    # deviation_loss = (-1 * deviation_loss).exp().sum(dim=-1).mean()\n",
    "    \n",
    "    return (class_loss + alpha * loc_loss), {\"class_loss\": class_loss, \"loc_loss\": loc_loss}\n",
    "\n",
    "\n",
    "def train(model,dataloader, criterion, optimizer, scheduler=None, freeze_conv=False):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    training_loss = []\n",
    "    \n",
    "    for idx, (x, y) in enumerate(pbar := tqdm(dataloader)):\n",
    "        \n",
    "        x, y_class, y_loc = x.to(DEVICE), y[0].to(DEVICE), y[1].to(DEVICE)\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "            pred_class, pred_loc = model(x, freeze_conv=freeze_conv)\n",
    "            pred_loc = pred_loc.reshape(-1,5,2)\n",
    "            loss, _ = criterion(y_class, y_loc, pred_class, pred_loc)\n",
    "            loss = loss / GRAD_ACC\n",
    "            \n",
    "        loss.backward()\n",
    "        norm = nn.utils.clip_grad_norm(model.parameters(), 1.0)\n",
    "\n",
    "        training_loss.append(loss.item() * GRAD_ACC)\n",
    "\n",
    "        if (idx + 1) % GRAD_ACC == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "\n",
    "        pbar.set_description(f\"loss: {loss.item() * GRAD_ACC:.6f}, | norm: {norm:.4f}| training_loss: {np.mean(training_loss):.6f}\")\n",
    "        \n",
    "    \n",
    "    return np.mean(training_loss)\n",
    "\n",
    "def validation(model, data_loader, criterion):\n",
    "    \n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = []\n",
    "        loc_loss = []\n",
    "        class_loss = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "    \n",
    "            for idx, (x, y) in enumerate(pbar := tqdm(data_loader)):\n",
    "                \n",
    "                x, y_class, y_loc = x.to(DEVICE).squeeze(0).float(), y[0].to(DEVICE).squeeze(0), y[1].to(DEVICE).squeeze(0)\n",
    "\n",
    "                with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "                    pred_class, pred_loc = model(x)\n",
    "                    pred_loc = pred_loc.reshape(-1,5,2)\n",
    "                    loss, per_cat_loss = criterion(y_class, y_loc, pred_class, pred_loc)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "                loc_loss.append(per_cat_loss[\"loc_loss\"].item())\n",
    "                class_loss.append(per_cat_loss[\"class_loss\"].item())\n",
    "                \n",
    "    \n",
    "                pbar.set_description(f\"current loss: {loss.item():.6f}, validation_loss: {np.mean(val_loss):.6f}, loc_loss: {np.mean(loc_loss)}, class_loss: {np.mean(class_loss)}\")\n",
    "\n",
    "        return np.mean(val_loss), np.mean(loc_loss), np.mean(class_loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3f8b286-ba28-402e-98fa-a27288b3a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a110b3c9-9658-4b41-9cb4-197a813d153f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "start fold0\n",
      "##############################\n",
      "1579 395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                  | 0/98 [00:00<?, ?it/s]/tmp/ipykernel_90767/202607252.py:31: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  norm = nn.utils.clip_grad_norm(model.parameters(), 1.0)\n",
      "loss: 1.387324, | norm: 0.9872| training_loss: 2.145542: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.88it/s]\n",
      "current loss: 0.353810, validation_loss: 0.355342, loc_loss: 21.4514547046671, class_loss: 0.14082731581196722: 100%|███████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3553 | loc_loss: 21.4515 | class_loss: 0.1408\n",
      "updating best_loc_loss from 23.73 to 21.4514547046671\n",
      "updated losses: best_val_loss=0.35534186285863817, best_loc_loss=21.4514547046671, best_class_loss=0.14082731581196722\n",
      "Saving model....\n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.635445, | norm: 3.0989| training_loss: 1.340469: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.97it/s]\n",
      "current loss: 0.105650, validation_loss: 0.202759, loc_loss: 9.412917527264975, class_loss: 0.10862943601305679: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.2028 | loc_loss: 9.4129 | class_loss: 0.1086\n",
      "updating best_loc_loss from 21.4514547046671 to 9.412917527264975\n",
      "updated losses: best_val_loss=0.20275861128570652, best_loc_loss=9.412917527264975, best_class_loss=0.10862943601305679\n",
      "Saving model....\n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.591357, | norm: 3.2954| training_loss: 0.772919: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.97it/s]\n",
      "current loss: 0.204330, validation_loss: 0.166247, loc_loss: 5.048943918212257, class_loss: 0.11575759505910342: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1662 | loc_loss: 5.0489 | class_loss: 0.1158\n",
      "updating best_loc_loss from 9.412917527264975 to 5.048943918212257\n",
      "updated losses: best_val_loss=0.16624703424122597, best_loc_loss=5.048943918212257, best_class_loss=0.11575759505910342\n",
      "Saving model....\n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.521424, | norm: 1.9476| training_loss: 0.643112: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.96it/s]\n",
      "current loss: 0.128305, validation_loss: 0.153775, loc_loss: 5.342581588767091, class_loss: 0.10034916021128214: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1538 | loc_loss: 5.3426 | class_loss: 0.1003\n",
      "2 more epochs to train until early stopping\n",
      "EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.845688, | norm: 2.0131| training_loss: 0.595059: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.95it/s]\n",
      "current loss: 0.122777, validation_loss: 0.177357, loc_loss: 2.564394206923018, class_loss: 0.15171258658556475: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1774 | loc_loss: 2.5644 | class_loss: 0.1517\n",
      "updating best_loc_loss from 5.048943918212257 to 2.564394206923018\n",
      "updated losses: best_val_loss=0.1773565286547949, best_loc_loss=2.564394206923018, best_class_loss=0.15171258658556475\n",
      "Saving model....\n",
      "EPOCH: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.320820, | norm: 0.7335| training_loss: 0.556414: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.97it/s]\n",
      "current loss: 0.116682, validation_loss: 0.133097, loc_loss: 2.452357751670542, class_loss: 0.1085732844816102: 100%|███████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1331 | loc_loss: 2.4524 | class_loss: 0.1086\n",
      "updating best_loc_loss from 2.564394206923018 to 2.452357751670542\n",
      "updated losses: best_val_loss=0.1330968619983156, best_loc_loss=2.452357751670542, best_class_loss=0.1085732844816102\n",
      "Saving model....\n",
      "EPOCH: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.478092, | norm: 0.9823| training_loss: 0.517948: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.96it/s]\n",
      "current loss: 0.118192, validation_loss: 0.136565, loc_loss: 2.869341364225574, class_loss: 0.10787161663431442: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1366 | loc_loss: 2.8693 | class_loss: 0.1079\n",
      "2 more epochs to train until early stopping\n",
      "EPOCH: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.532738, | norm: 0.9167| training_loss: 0.515242: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.95it/s]\n",
      "current loss: 0.093693, validation_loss: 0.114436, loc_loss: 2.2872040105593996, class_loss: 0.0915641614900358: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 23.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1144 | loc_loss: 2.2872 | class_loss: 0.0916\n",
      "updating best_loc_loss from 2.452357751670542 to 2.2872040105593996\n",
      "updated losses: best_val_loss=0.1144362015956298, best_loc_loss=2.2872040105593996, best_class_loss=0.0915641614900358\n",
      "Saving model....\n",
      "EPOCH: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.366808, | norm: 1.6627| training_loss: 0.504227: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.97it/s]\n",
      "current loss: 0.058913, validation_loss: 0.117860, loc_loss: 3.283518595992037, class_loss: 0.08502473178621427: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1179 | loc_loss: 3.2835 | class_loss: 0.0850\n",
      "2 more epochs to train until early stopping\n",
      "EPOCH: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.315224, | norm: 1.8625| training_loss: 0.499047: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.98it/s]\n",
      "current loss: 0.044555, validation_loss: 0.107406, loc_loss: 2.273886434290267, class_loss: 0.08466739243361468: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1074 | loc_loss: 2.2739 | class_loss: 0.0847\n",
      "updating best_loc_loss from 2.2872040105593996 to 2.273886434290267\n",
      "updated losses: best_val_loss=0.10740625677651736, best_loc_loss=2.273886434290267, best_class_loss=0.08466739243361468\n",
      "Saving model....\n",
      "EPOCH: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.510382, | norm: 1.5626| training_loss: 0.458336: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.96it/s]\n",
      "current loss: 0.042918, validation_loss: 0.115060, loc_loss: 2.095956577258987, class_loss: 0.09410079569048214: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1151 | loc_loss: 2.0960 | class_loss: 0.0941\n",
      "updating best_loc_loss from 2.273886434290267 to 2.095956577258987\n",
      "updated losses: best_val_loss=0.11506036146307203, best_loc_loss=2.095956577258987, best_class_loss=0.09410079569048214\n",
      "Saving model....\n",
      "EPOCH: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.598295, | norm: 1.7582| training_loss: 0.435402: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.95it/s]\n",
      "current loss: 0.046234, validation_loss: 0.110409, loc_loss: 2.3258150296907303, class_loss: 0.08715067255792946: 100%|█████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1104 | loc_loss: 2.3258 | class_loss: 0.0872\n",
      "2 more epochs to train until early stopping\n",
      "EPOCH: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.483331, | norm: 1.2603| training_loss: 0.459344: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.96it/s]\n",
      "current loss: 0.042663, validation_loss: 0.104709, loc_loss: 2.2788772699558653, class_loss: 0.0819197365962784: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1047 | loc_loss: 2.2789 | class_loss: 0.0819\n",
      "1 more epochs to train until early stopping\n",
      "EPOCH: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.453947, | norm: 1.6297| training_loss: 0.473196: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.96it/s]\n",
      "current loss: 0.034294, validation_loss: 0.106067, loc_loss: 2.1701005231963064, class_loss: 0.08436586995606281: 100%|█████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1061 | loc_loss: 2.1701 | class_loss: 0.0844\n",
      "0 more epochs to train until early stopping\n",
      "##############################\n",
      "start fold1\n",
      "##############################\n",
      "1579 395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.944486, | norm: 1.6336| training_loss: 2.150617: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.95it/s]\n",
      "current loss: 0.355796, validation_loss: 0.341588, loc_loss: 22.297437794011977, class_loss: 0.11861378499879396: 100%|█████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3416 | loc_loss: 22.2974 | class_loss: 0.1186\n",
      "updating best_loc_loss from 23.73 to 22.297437794011977\n",
      "updated losses: best_val_loss=0.34158816293891375, best_loc_loss=22.297437794011977, best_class_loss=0.11861378499879396\n",
      "Saving model....\n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.691881, | norm: 1.4545| training_loss: 1.368517: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.97it/s]\n",
      "current loss: 0.241109, validation_loss: 0.219915, loc_loss: 9.877090135831015, class_loss: 0.12114370719628367: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.2199 | loc_loss: 9.8771 | class_loss: 0.1211\n",
      "updating best_loc_loss from 22.297437794011977 to 9.877090135831015\n",
      "updated losses: best_val_loss=0.21991460855459383, best_loc_loss=9.877090135831015, best_class_loss=0.12114370719628367\n",
      "Saving model....\n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.646685, | norm: 2.7839| training_loss: 0.671196: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.98it/s]\n",
      "current loss: 0.176212, validation_loss: 0.181527, loc_loss: 7.834534646863507, class_loss: 0.10318116116772784: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1815 | loc_loss: 7.8345 | class_loss: 0.1032\n",
      "updating best_loc_loss from 9.877090135831015 to 7.834534646863507\n",
      "updated losses: best_val_loss=0.18152650763636288, best_loc_loss=7.834534646863507, best_class_loss=0.10318116116772784\n",
      "Saving model....\n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.588082, | norm: 1.7677| training_loss: 0.590630: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.98it/s]\n",
      "current loss: 0.340816, validation_loss: 0.123427, loc_loss: 3.831232129216637, class_loss: 0.08511483431218707: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1234 | loc_loss: 3.8312 | class_loss: 0.0851\n",
      "updating best_loc_loss from 7.834534646863507 to 3.831232129216637\n",
      "updated losses: best_val_loss=0.12342715560435345, best_loc_loss=3.831232129216637, best_class_loss=0.08511483431218707\n",
      "Saving model....\n",
      "EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.413472, | norm: 0.8413| training_loss: 0.609645: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.95it/s]\n",
      "current loss: 0.183605, validation_loss: 0.109643, loc_loss: 2.7342797938788888, class_loss: 0.08229991296708677: 100%|█████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1096 | loc_loss: 2.7343 | class_loss: 0.0823\n",
      "updating best_loc_loss from 3.831232129216637 to 2.7342797938788888\n",
      "updated losses: best_val_loss=0.10964271090587568, best_loc_loss=2.7342797938788888, best_class_loss=0.08229991296708677\n",
      "Saving model....\n",
      "EPOCH: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.406147, | norm: 1.8902| training_loss: 0.531100: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.98it/s]\n",
      "current loss: 0.155147, validation_loss: 0.114981, loc_loss: 2.8546319051324853, class_loss: 0.08643479059436757: 100%|█████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1150 | loc_loss: 2.8546 | class_loss: 0.0864\n",
      "2 more epochs to train until early stopping\n",
      "EPOCH: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.758090, | norm: 11.5623| training_loss: 0.529112: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.96it/s]\n",
      "current loss: 0.162502, validation_loss: 0.112638, loc_loss: 2.7446408942355385, class_loss: 0.0851918568335952: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1126 | loc_loss: 2.7446 | class_loss: 0.0852\n",
      "1 more epochs to train until early stopping\n",
      "EPOCH: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.436277, | norm: 18.7677| training_loss: 0.492680: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.95it/s]\n",
      "current loss: 0.145143, validation_loss: 0.108474, loc_loss: 2.4781810811023273, class_loss: 0.08369224743919924: 100%|█████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1085 | loc_loss: 2.4782 | class_loss: 0.0837\n",
      "updating best_loc_loss from 2.7342797938788888 to 2.4781810811023273\n",
      "updated losses: best_val_loss=0.10847405825022252, best_loc_loss=2.4781810811023273, best_class_loss=0.08369224743919924\n",
      "Saving model....\n",
      "EPOCH: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.510440, | norm: 1.4326| training_loss: 0.487366: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.96it/s]\n",
      "current loss: 0.180905, validation_loss: 0.119986, loc_loss: 2.3334471069020792, class_loss: 0.0966511379586337: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1200 | loc_loss: 2.3334 | class_loss: 0.0967\n",
      "updating best_loc_loss from 2.4781810811023273 to 2.3334471069020792\n",
      "updated losses: best_val_loss=0.11998560902765448, best_loc_loss=2.3334471069020792, best_class_loss=0.0966511379586337\n",
      "Saving model....\n",
      "EPOCH: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.262648, | norm: 1.3993| training_loss: 0.478989: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  6.02it/s]\n",
      "current loss: 0.229063, validation_loss: 0.121763, loc_loss: 2.5372246691179297, class_loss: 0.09639066893861757: 100%|█████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:16<00:00, 23.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1218 | loc_loss: 2.5372 | class_loss: 0.0964\n",
      "2 more epochs to train until early stopping\n",
      "EPOCH: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.413658, | norm: 0.9801| training_loss: 0.447556: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  6.03it/s]\n",
      "current loss: 0.198070, validation_loss: 0.105824, loc_loss: 2.257636429255242, class_loss: 0.08324781994258745: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:16<00:00, 23.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1058 | loc_loss: 2.2576 | class_loss: 0.0832\n",
      "updating best_loc_loss from 2.3334471069020792 to 2.257636429255242\n",
      "updated losses: best_val_loss=0.10582418423513988, best_loc_loss=2.257636429255242, best_class_loss=0.08324781994258745\n",
      "Saving model....\n",
      "EPOCH: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.431733, | norm: 0.7106| training_loss: 0.449761: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  6.02it/s]\n",
      "current loss: 0.278036, validation_loss: 0.119473, loc_loss: 2.2000340228236985, class_loss: 0.09747249733098795: 100%|█████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:16<00:00, 23.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1195 | loc_loss: 2.2000 | class_loss: 0.0975\n",
      "updating best_loc_loss from 2.257636429255242 to 2.2000340228236985\n",
      "updated losses: best_val_loss=0.11947283755922493, best_loc_loss=2.2000340228236985, best_class_loss=0.09747249733098795\n",
      "Saving model....\n",
      "EPOCH: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.721791, | norm: 6.8528| training_loss: 0.462586: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  6.02it/s]\n",
      "current loss: 0.231584, validation_loss: 0.110060, loc_loss: 2.276949420268124, class_loss: 0.08729096845637208: 100%|██████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:16<00:00, 23.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1101 | loc_loss: 2.2769 | class_loss: 0.0873\n",
      "2 more epochs to train until early stopping\n",
      "EPOCH: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.760068, | norm: 2.2941| training_loss: 0.421293: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.97it/s]\n",
      "current loss: 0.240540, validation_loss: 0.111460, loc_loss: 2.1282476730248274, class_loss: 0.09017778744723498: 100%|█████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1115 | loc_loss: 2.1282 | class_loss: 0.0902\n",
      "updating best_loc_loss from 2.2000340228236985 to 2.1282476730248274\n",
      "updated losses: best_val_loss=0.11146026417748325, best_loc_loss=2.1282476730248274, best_class_loss=0.09017778744723498\n",
      "Saving model....\n",
      "EPOCH: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.564474, | norm: 3.1651| training_loss: 0.435414: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:16<00:00,  5.96it/s]\n",
      "current loss: 0.282130, validation_loss: 0.115324, loc_loss: 2.1901327224135954, class_loss: 0.09342236881265933: 100%|█████████████████████████████████████████████████████████████████████████████████████| 395/395 [00:17<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1153 | loc_loss: 2.1901 | class_loss: 0.0934\n",
      "2 more epochs to train until early stopping\n",
      "##############################\n",
      "start fold2\n",
      "##############################\n",
      "1579 395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.316605, | norm: 0.5060| training_loss: 2.299715:  12%|█████████████████▋                                                                                                                              | 12/98 [00:02<00:16,  5.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreeze_conv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     val_loss, loc_loss, class_loss \u001b[38;5;241m=\u001b[39m validation(model, valid_dl, criterion)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | loc_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloc_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | class_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, criterion, optimizer, scheduler, freeze_conv)\u001b[0m\n\u001b[1;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     31\u001b[0m norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m training_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m GRAD_ACC)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m GRAD_ACC \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     36\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(range(len(df)))):\n",
    "    print('#'*30)\n",
    "    print(f'start fold{fold}')\n",
    "    print('#'*30)\n",
    "    print(len(trn_idx), len(val_idx))\n",
    "    \n",
    "    df_train = df.iloc[trn_idx]\n",
    "    df_valid = df.iloc[val_idx]\n",
    "    \n",
    "    train_ds = RSNA24Dataset(df_train[\"study_id\"].unique(), phase='train', transformations=[vertical_flip, horizontal_flip])\n",
    "    train_dl = DataLoader(\n",
    "                train_ds,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                pin_memory=True,\n",
    "                drop_last=True,\n",
    "                num_workers=N_WORKERS\n",
    "                )\n",
    "\n",
    "    valid_ds = RSNA24Dataset(df_valid[\"study_id\"].unique(), phase='valid', transformations=[])\n",
    "    valid_dl = DataLoader(\n",
    "                valid_ds,\n",
    "                batch_size=1,\n",
    "                shuffle=False,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "                num_workers=N_WORKERS\n",
    "                )\n",
    "    \n",
    "    model = RSNA24Model(MODEL_NAME).to(DEVICE)\n",
    "    optimizer = AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "    \n",
    "    warmup_steps = EPOCHS/10 * len(train_dl) // GRAD_ACC\n",
    "    num_total_steps = EPOCHS * len(train_dl) // GRAD_ACC\n",
    "    num_cycles = 0.475\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=warmup_steps,\n",
    "                                                num_training_steps=num_total_steps,\n",
    "                                                num_cycles=num_cycles)\n",
    "\n",
    "    best_val_loss   = 1.04\n",
    "    best_loc_loss   = 23.73\n",
    "    best_class_loss = 0.80\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print(f\"EPOCH: {epoch}\")\n",
    "        _ = train(model, train_dl, criterion, optimizer, scheduler, freeze_conv=False)\n",
    "        val_loss, loc_loss, class_loss = validation(model, valid_dl, criterion)\n",
    "\n",
    "        print(f\"val_loss: {val_loss:.4f} | loc_loss: {loc_loss:.4f} | class_loss: {class_loss:.4f}\")\n",
    "\n",
    "        if loc_loss < best_loc_loss:\n",
    "            early_stop_counter = 0\n",
    "            print(f\"updating best_loc_loss from {best_loc_loss} to {loc_loss}\")\n",
    "            \n",
    "            best_val_loss = val_loss\n",
    "            best_loc_loss = loc_loss\n",
    "            best_class_loss = class_loss\n",
    "\n",
    "            print(f\"updated losses: {best_val_loss=}, {best_loc_loss=}, {best_class_loss=}\")\n",
    "\n",
    "            print(\"Saving model....\")\n",
    "            fname = f'{OUTPUT_DIR}/best_loc_model_fold-{fold}.pt'\n",
    "            torch.save(model.state_dict(), fname)\n",
    "            \n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            print(f\"{EARLY_STOPPING_EPOCH - early_stop_counter} more epochs to train until early stopping\")\n",
    "\n",
    "        if early_stop_counter == EARLY_STOPPING_EPOCH:\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ebe21-336b-4eca-8a16-80fccacfebf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
